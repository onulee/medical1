{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'xray_classification_pneumonia'...\n",
      "Updating files:  41% (2446/5846)\n",
      "Updating files:  42% (2456/5846)\n",
      "Updating files:  43% (2514/5846)\n",
      "Updating files:  44% (2573/5846)\n",
      "Updating files:  45% (2631/5846)\n",
      "Updating files:  46% (2690/5846)\n",
      "Updating files:  47% (2748/5846)\n",
      "Updating files:  48% (2807/5846)\n",
      "Updating files:  49% (2865/5846)\n",
      "Updating files:  50% (2923/5846)\n",
      "Updating files:  51% (2982/5846)\n",
      "Updating files:  52% (3040/5846)\n",
      "Updating files:  53% (3099/5846)\n",
      "Updating files:  54% (3157/5846)\n",
      "Updating files:  55% (3216/5846)\n",
      "Updating files:  56% (3274/5846)\n",
      "Updating files:  57% (3333/5846)\n",
      "Updating files:  58% (3391/5846)\n",
      "Updating files:  59% (3450/5846)\n",
      "Updating files:  60% (3508/5846)\n",
      "Updating files:  61% (3567/5846)\n",
      "Updating files:  62% (3625/5846)\n",
      "Updating files:  63% (3683/5846)\n",
      "Updating files:  64% (3742/5846)\n",
      "Updating files:  65% (3800/5846)\n",
      "Updating files:  66% (3859/5846)\n",
      "Updating files:  67% (3917/5846)\n",
      "Updating files:  68% (3976/5846)\n",
      "Updating files:  69% (4034/5846)\n",
      "Updating files:  70% (4093/5846)\n",
      "Updating files:  71% (4151/5846)\n",
      "Updating files:  72% (4210/5846)\n",
      "Updating files:  73% (4268/5846)\n",
      "Updating files:  74% (4327/5846)\n",
      "Updating files:  75% (4385/5846)\n",
      "Updating files:  76% (4443/5846)\n",
      "Updating files:  77% (4502/5846)\n",
      "Updating files:  78% (4560/5846)\n",
      "Updating files:  79% (4619/5846)\n",
      "Updating files:  80% (4677/5846)\n",
      "Updating files:  81% (4736/5846)\n",
      "Updating files:  82% (4794/5846)\n",
      "Updating files:  82% (4843/5846)\n",
      "Updating files:  83% (4853/5846)\n",
      "Updating files:  84% (4911/5846)\n",
      "Updating files:  85% (4970/5846)\n",
      "Updating files:  86% (5028/5846)\n",
      "Updating files:  87% (5087/5846)\n",
      "Updating files:  88% (5145/5846)\n",
      "Updating files:  89% (5203/5846)\n",
      "Updating files:  90% (5262/5846)\n",
      "Updating files:  91% (5320/5846)\n",
      "Updating files:  92% (5379/5846)\n",
      "Updating files:  93% (5437/5846)\n",
      "Updating files:  94% (5496/5846)\n",
      "Updating files:  95% (5554/5846)\n",
      "Updating files:  96% (5613/5846)\n",
      "Updating files:  97% (5671/5846)\n",
      "Updating files:  98% (5730/5846)\n",
      "Updating files:  99% (5788/5846)\n",
      "Updating files: 100% (5846/5846)\n",
      "Updating files: 100% (5846/5846), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/anantSinghCross/xray_classification_pneumonia.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\workspace\\\\medical1\\\\p0604-13'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "base_path = './xray_classification_pneumonia/Dataset_compressed/train'\n",
    "file_path = list(glob.glob(base_path + \"/*/*.*\"))\n",
    "\n",
    "pneumonia = list(glob.glob(base_path+\"/PNEUMONIA/*.*\"))\n",
    "normal = list(glob.glob(base_path+\"/NORMAL/*.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3875, 1341)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pneumonia), len(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./xray_classification_pneumonia/Dataset_compressed/train\\NORMAL\n",
      "('./xray_classification_pneumonia/Dataset_compressed', 'train')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "test = os.path.dirname(file_path[0])\n",
    "print(test)\n",
    "class_name = os.path.split(os.path.dirname(test))\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name to label\n",
    "labels = []\n",
    "\n",
    "for fp in file_path:\n",
    "    tmp = os.path.dirname(fp)\n",
    "    class_name = os.path.split(tmp)\n",
    "    if class_name[1] == \"PNEUMONIA\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "3000 images to array\n",
      "3250 images to array\n",
      "3500 images to array\n",
      "3750 images to array\n",
      "4000 images to array\n",
      "4250 images to array\n",
      "4500 images to array\n",
      "4750 images to array\n",
      "5000 images to array\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "\n",
    "img_width = 60\n",
    "img_height = 60\n",
    "\n",
    "dataset = np.ndarray(shape=(len(file_path), img_height*img_width), dtype=np.float32)\n",
    "\n",
    "i=0\n",
    "for _file in file_path:\n",
    "    img = cv2.imread(_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (img_width, img_height))\n",
    "    \n",
    "    dataset[i] = img_resized.flatten()\n",
    "    i += 1\n",
    "    if i % 250 == 0:\n",
    "        print(f\"{i} images to array\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom - 계산을 안정적으로 처리\n",
    "def sigmoid(x):\n",
    "    pos_mask = (x>=0)\n",
    "    neg_mask = (x<0)\n",
    "    z = np.zeros_like(x) # 입력 값과 같은 크기의 배열을 0으로 생성\n",
    "    z[pos_mask] = np.exp(-x[pos_mask])\n",
    "    z[neg_mask] = np.exp(x[neg_mask])\n",
    "    top = np.ones_like(x)\n",
    "    top[neg_mask] = z[neg_mask] #입력 값이 0보다 작은 경우 분자를 exp(x) 설정\n",
    "    return top / (1+z) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "def softmax(x):\n",
    "    c = np.max(x)\n",
    "    exp_x = np.exp(x-c)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    y = exp_x / sum_exp_x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.random.randn(3600*100).reshape((3600, 100))\n",
    "    network['b1'] = np.random.randn(100)\n",
    "    network['W2'] = np.random.randn(100*50).reshape((100, 50))\n",
    "    network['b2'] = np.random.randn(50)\n",
    "    network['W3'] = np.random.randn(50*2).reshape((50, 2))\n",
    "    network['b3'] = np.random.randn(2)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def identify_function(x):\n",
    "    return x\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7429064417177914\n"
     ]
    }
   ],
   "source": [
    "x, t = dataset, labels\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy: \" + str(float(accuracy_cnt/len(x))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
